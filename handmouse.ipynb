{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import utils\n",
    "import pyautogui\n",
    "import keyboard\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_w, screen_h = pyautogui.size()\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity = 1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    max_num_hands = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_landmark_cordinates(processed,index,frame):\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        if processed.multi_hand_landmarks:\n",
    "                hand_landmarks = processed.multi_hand_landmarks[0]\n",
    "                x = int(hand_landmarks.landmark[index].x * frame_w)\n",
    "                y = int(hand_landmarks.landmark[index].y * frame_h)\n",
    "                return (x,y)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(processed,frame):\n",
    "    index_finger_tip = find_landmark_cordinates(processed,8,frame)\n",
    "    thumb_finger_tip = find_landmark_cordinates(processed,4,frame)\n",
    "    wrist = find_landmark_cordinates(processed,0,frame)\n",
    "    middle_figer_tip = find_landmark_cordinates(processed,12,frame)\n",
    "\n",
    "    if index_finger_tip:\n",
    "        cv2.circle(frame, (index_finger_tip[0],index_finger_tip[1]), 10, (0,255,0), 2)\n",
    "    if thumb_finger_tip:\n",
    "        cv2.circle(frame, (thumb_finger_tip[0],thumb_finger_tip[1]), 10, (255,125,0), 2)\n",
    "    if wrist:\n",
    "        cv2.circle(frame, (wrist[0],wrist[1]), 10, (0,255,255), 2)\n",
    "    if middle_figer_tip:\n",
    "        cv2.circle(frame, (middle_figer_tip[0],middle_figer_tip[1]), 10, (255,255,86), 2)\n",
    "\n",
    "\n",
    "\n",
    "def draw_triangle(middle_cordinates,frame):\n",
    "    cx, cy = middle_cordinates\n",
    "    size = 30\n",
    "    half_size = size / 2\n",
    "    color = (210,0,255)\n",
    "    thickness = 2\n",
    "    pt1 = (int(cx), int(cy - half_size))\n",
    "    pt2 = (int(cx - half_size), int(cy + half_size))\n",
    "    pt3 = (int(cx + half_size), int(cy + half_size))  \n",
    "    triangle_cnt = np.array([pt1, pt2, pt3])\n",
    "    cv2.drawContours(frame, [triangle_cnt], 0, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_gesture = False\n",
    "first_cord_captured = False\n",
    "initial_cord = ()\n",
    "hand_closed_start_time = None\n",
    "def detect_gestures(frame,landmarks_list,processed):\n",
    "    global can_gesture\n",
    "    global initial_cord\n",
    "    global first_cord_captured\n",
    "    global hand_closed_start_time\n",
    "\n",
    "    min_volume = 30\n",
    "    max_volume = 250\n",
    "    max_hand_closed_timer = 1\n",
    "\n",
    "\n",
    "    if len(landmarks_list) >= 21:\n",
    "        middle_wrist_dist = utils.get_distance([landmarks_list[12],landmarks_list[0]])\n",
    "        thumb_index_dist = utils.get_distance([landmarks_list[8],landmarks_list[4]])\n",
    "        \n",
    "\n",
    "        current_cord = ()\n",
    "        if middle_wrist_dist > 290:\n",
    "            can_gesture = True\n",
    "            hand_closed_start_time = None\n",
    "\n",
    "            if not first_cord_captured:\n",
    "                initial_cord = find_landmark_cordinates(processed,8,frame)            \n",
    "                first_cord_captured = True\n",
    "            else:\n",
    "                current_cord = find_landmark_cordinates(processed,8,frame)\n",
    "        else:\n",
    "            if hand_closed_start_time is None:\n",
    "                hand_closed_start_time = time.time()\n",
    "            elif (time.time() - hand_closed_start_time) > max_hand_closed_timer: \n",
    "                can_gesture = False\n",
    "                first_cord_captured = False\n",
    "\n",
    "        #Draw number of distances\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        string = \"IW:{0} TI:{1}\".format(str(int(middle_wrist_dist)),str(int(thumb_index_dist)))\n",
    "        cv2.putText(frame, string, (int(frame_w / 2) - 200, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (167,191,62), 3)\n",
    "\n",
    "        #Draw ready trinagle on initial cordinate \n",
    "        if first_cord_captured:\n",
    "            draw_triangle(initial_cord,frame)\n",
    "        \n",
    "        if can_gesture:\n",
    "\n",
    "            if first_cord_captured and current_cord:\n",
    "                if initial_cord[0] > frame_w / 2 and current_cord[0] < frame_w / 2:\n",
    "                    keyboard.send(\"next track\")\n",
    "                    initial_cord = ()\n",
    "                    first_cord_captured = False\n",
    "                elif initial_cord[0] < frame_w / 2 and current_cord[0] > frame_w / 2:\n",
    "                    keyboard.send(\"previous track\")\n",
    "                    initial_cord = ()\n",
    "                    first_cord_captured = False\n",
    "\n",
    "            volume_level = np.interp(thumb_index_dist, [min_volume, max_volume], [0, 100])\n",
    "\n",
    "            if thumb_index_dist < max_volume and middle_wrist_dist > 300:\n",
    "                if volume_level > 50:\n",
    "                    keyboard.send(\"Volume Up\")\n",
    "                elif volume_level < 50:\n",
    "                    keyboard.send(\"Volume Down\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Python\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(frame,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m frameRGB \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 13\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframeRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n",
      "File \u001b[1;32md:\\Code\\Python\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Python\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "draw = mp.solutions.drawing_utils\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed = hands.process(frameRGB)\n",
    "        \n",
    "        landmarks_list = []\n",
    "\n",
    "        if processed.multi_hand_landmarks:\n",
    "            hand_landkarms = processed.multi_hand_landmarks[0]\n",
    "            draw.draw_landmarks(frame, hand_landkarms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            for lm in hand_landkarms.landmark:\n",
    "                landmarks_list.append((lm.x,lm.y))\n",
    "        \n",
    "        draw_landmarks(processed,frame)\n",
    "        detect_gestures(frame,landmarks_list,processed)\n",
    "        \n",
    "        cv2.imshow('Frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
