{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import utils\n",
    "import pyautogui\n",
    "import keyboard\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_w, screen_h = pyautogui.size()\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,\n",
    "    model_complexity = 1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7,\n",
    "    max_num_hands = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_landmark_cordinates(processed,index,frame):\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        if processed.multi_hand_landmarks:\n",
    "                hand_landmarks = processed.multi_hand_landmarks[0]\n",
    "                x = int(hand_landmarks.landmark[index].x * frame_w)\n",
    "                y = int(hand_landmarks.landmark[index].y * frame_h)\n",
    "                return (x,y)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_mouse(index_finger_tip):\n",
    "    if index_finger_tip is not None:\n",
    "        x = int(index_finger_tip.x * screen_w)\n",
    "        y = int(index_finger_tip.y * screen_h)\n",
    "        pyautogui.moveTo(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_gesture = False\n",
    "first_cord_captured = False\n",
    "initial_cord = ()\n",
    "hand_closed_start_time = None\n",
    "def detect_gestures(frame,landmarks_list,processed):\n",
    "    global can_gesture\n",
    "    global initial_cord\n",
    "    global first_cord_captured\n",
    "    global hand_closed_start_time\n",
    "\n",
    "    min_volume = 30\n",
    "    max_volume = 300\n",
    "    max_hand_closed_timer = 1\n",
    "\n",
    "\n",
    "    if len(landmarks_list) >= 21:\n",
    "        index_wrist_dist = utils.get_distance([landmarks_list[8],landmarks_list[0]])\n",
    "        thumb_index_dist = utils.get_distance([landmarks_list[8],landmarks_list[4]])\n",
    "\n",
    "\n",
    "        current_cord = ()\n",
    "        if index_wrist_dist > 290:\n",
    "            can_gesture = True\n",
    "            hand_closed_start_time = None\n",
    "\n",
    "            if not first_cord_captured:\n",
    "                initial_cord = find_landmark_cordinates(processed,8,frame)            \n",
    "                first_cord_captured = True\n",
    "            else:\n",
    "                current_cord = find_landmark_cordinates(processed,8,frame)\n",
    "        else:\n",
    "            if hand_closed_start_time is None:\n",
    "                hand_closed_start_time = time.time()\n",
    "            elif (time.time() - hand_closed_start_time) > max_hand_closed_timer: \n",
    "                can_gesture = False\n",
    "                first_cord_captured = False\n",
    "\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        string = \"IW:{0} TI:{1}\".format(str(int(index_wrist_dist)),str(int(thumb_index_dist)))\n",
    "        cv2.putText(frame, string, (int(frame_w / 2) - 200, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (167,191,62), 3)\n",
    "\n",
    "        #Draw ready trinagle on initial cordinate \n",
    "        if first_cord_captured:\n",
    "            cx, cy = initial_cord\n",
    "            size = 30\n",
    "            half_size = size / 2\n",
    "            color = (210,0,255)\n",
    "            thickness = 2\n",
    "            pt1 = (int(cx), int(cy - half_size))  # Top\n",
    "            pt2 = (int(cx - half_size), int(cy + half_size))  # Bottom left\n",
    "            pt3 = (int(cx + half_size), int(cy + half_size))  # Bottom right\n",
    "            triangle_cnt = np.array([pt1, pt2, pt3])\n",
    "            cv2.drawContours(frame, [triangle_cnt], 0, color, thickness)\n",
    "            # cv2.circle(frame, (initial_cord[0],initial_cord[1]), 3, (0,0,0), 2)\n",
    "        \n",
    "        if first_cord_captured and current_cord and can_gesture:\n",
    "            \n",
    "            if initial_cord[0] > frame_w / 2 and current_cord[0] < frame_w / 2:\n",
    "                keyboard.send(\"next track\")\n",
    "                initial_cord = ()\n",
    "                first_cord_captured = False\n",
    "            elif initial_cord[0] < frame_w / 2 and current_cord[0] > frame_w / 2:\n",
    "                keyboard.send(\"previous track\")\n",
    "                initial_cord = ()\n",
    "                first_cord_captured = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(processed,frame):\n",
    "    index_finger_tip = find_landmark_cordinates(processed,8,frame)\n",
    "    thumb_finger_tip = find_landmark_cordinates(processed,4,frame)\n",
    "    wrist = find_landmark_cordinates(processed,0,frame)\n",
    "\n",
    "    if index_finger_tip:\n",
    "        cv2.circle(frame, (index_finger_tip[0],index_finger_tip[1]), 10, (0,255,0), 2)\n",
    "    if thumb_finger_tip:\n",
    "        cv2.circle(frame, (thumb_finger_tip[0],thumb_finger_tip[1]), 10, (255,125,0), 2)\n",
    "    if wrist:\n",
    "        cv2.circle(frame, (wrist[0],wrist[1]), 10, (0,255,255), 2)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "draw = mp.solutions.drawing_utils\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.flip(frame,1)\n",
    "        frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed = hands.process(frameRGB)\n",
    "        \n",
    "        landmarks_list = []\n",
    "\n",
    "        if processed.multi_hand_landmarks:\n",
    "            hand_landkarms = processed.multi_hand_landmarks[0]\n",
    "            draw.draw_landmarks(frame, hand_landkarms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "            for lm in hand_landkarms.landmark:\n",
    "                landmarks_list.append((lm.x,lm.y))\n",
    "        \n",
    "        draw_landmarks(processed,frame)\n",
    "        detect_gestures(frame,landmarks_list,processed)\n",
    "        \n",
    "        cv2.imshow('Frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
